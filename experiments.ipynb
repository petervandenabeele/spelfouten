{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "sample_file_name = \"../dutch-language/data/sample-sentences-nlwiki.txt\"\n",
    "short_file_name = \"../dutch-language/data/short-sentences-nlwiki.txt\"\n",
    "full_file_name = \"../dutch-language/data/clean-sentences-nlwiki.txt\"\n",
    "corrected_file_name = \"../dutch-language/data/corrected-sentences-nlwiki.txt\"\n",
    "\n",
    "sentences_file_name = corrected_file_name\n",
    "positives_file_name = \"../dutch-language/data/positive-sentences-002.txt\"\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "TOTAL_SIZE = 10000000\n",
    "\n",
    "regex_nd = re.compile(r'.*')\n",
    "\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/RoBERTa-004\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "with open(sentences_file_name, 'r') as sentences_file:\n",
    "    with open(positives_file_name, 'w') as positives_file:\n",
    "        total_count = 0\n",
    "        match_count = 0\n",
    "        batch = []\n",
    "        batch_count = len(batch)\n",
    "\n",
    "        for line in sentences_file:\n",
    "            # process lines\n",
    "            clean_line = line.rstrip()\n",
    "            if (regex_nd.match(clean_line)):\n",
    "                match_count += 1\n",
    "\n",
    "                # fill batch\n",
    "                batch_count += 1\n",
    "                batch.append(clean_line)\n",
    "                if batch_count >= BATCH_SIZE:\n",
    "                    # process batch\n",
    "                    predictions, raw_outputs = model.predict(batch)\n",
    "                    for index in range(len(predictions)):\n",
    "                        is_positive = (predictions[index] == 1) # can be more subtle later; no, maybe, true\n",
    "                        if (is_positive):\n",
    "                            positives_file.write(f\"1\\t{raw_outputs[index][0]}\\t{raw_outputs[index][1]}\\t{batch[index]}\\n\")\n",
    "                    batch = []\n",
    "                    batch_count = len(batch)\n",
    "\n",
    "            # total count\n",
    "            total_count += 1\n",
    "            if (total_count >= TOTAL_SIZE):\n",
    "                break\n",
    "\n",
    "\n",
    "print()\n",
    "print(total_count)\n",
    "print(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/RoBERTa-003\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\n",
    "    \"Ik word nieuwsgierig.\",\n",
    "    \"Hoe word je gevraagd?\",\n",
    "    \"Wat wordt je gevraagd?\",\n",
    "    \"Wat word je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zend een pakje.\",\n",
    "    \"Ik zend je een pakje.\",\n",
    "    \"Ik zend u een heel mooie trui.\",\n",
    "    \"Je zendt het toch nog vandaag op, hoop ik.\", #\n",
    "    \"Jij zendt een hele grote doos naar oma.\",\n",
    "    \"Zend je dat straks uit?\", #\n",
    "    \"Zend jij echt die fiets via de post?\",\n",
    "    \"Welke baas zendt je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik wordt nieuwsgierig.\",\n",
    "    \"Hoe wordt je gevraagd?\",\n",
    "    \"Wat word je gevraagd?\",\n",
    "    \"Wat wordt je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zendt een pakje.\",\n",
    "    \"Ik zendt je een pakje.\",\n",
    "    \"Ik zendt u een heel mooie trui.\", #\n",
    "    \"Je zend het toch nog vandaag op, hoop ik.\",\n",
    "    \"Jij zend een hele grote doos naar oma.\",\n",
    "    \"Zendt je dat straks uit?\", #\n",
    "    \"Zendt jij echt die fiets via de post?\",\n",
    "    \"Welke baas zend je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # Trying other words\n",
    "    # Correct spelling\n",
    "    \"Ik vind dit toch niet zo mooi.\",\n",
    "    \"Wat vind jij van al die aandacht?\",\n",
    "    \"Hoe vind ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vindt.\",\n",
    "    \"Hoe zwaar vindt hij de opleiding?\",\n",
    "\n",
    "    \"Ik loop er zo maar voorbij.\",\n",
    "    \"Loop jij ook zo snel?\",\n",
    "    \"Je loopt daar beter niet telkens over.\",\n",
    "    \"Jij loopt echt helemaal naar zee?\",\n",
    "    \"En daarom loopt hij er met een grote bocht omheen.\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik vindt dit toch niet zo mooi.\",\n",
    "    \"Wat vindt jij van al die aandacht?\",\n",
    "    \"Hoe vindt ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vind.\", # Incorrectly evaluated to \"0\"\n",
    "    \"Hoe zwaar vind hij de opleiding?\",\n",
    "\n",
    "    \"Ik loopt er zo maar voorbij.\",\n",
    "    \"Loopt jij ook zo snel?\",\n",
    "    \"Je loop daar beter niet telkens over.\",\n",
    "    \"Jij loop echt helemaal naar zee?\",\n",
    "    \"En daarom loop hij er met een grote bocht omheen.\"\n",
    "])\n",
    "print()\n",
    "print(predictions)\n",
    "print(raw_outputs)\n",
    "\n",
    "# Expected           [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-002 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1]\n",
    "# Actual RoBERTa-003 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual    BERT-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the strong positives (fp) to examples negatives\n",
    "# cat positive-sentences-processed.txt | grep '^1.*\\-[34]\\.' | sed 's/.*\\t\\(..*\\)$/    [\"\\1\", 0],/' > strong-positives-to-correct.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bita71a60f45b8e4338b01992b37d5c2d2a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}