{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n<class 'simpletransformers.classification.classification_model.ClassificationModel'>\n100%|██████████| 100/100 [00:00<00:00, 1085.77it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.29it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 845.29it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.22it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1083.44it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.21it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1034.16it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.25it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1094.28it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.27it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1024.87it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.19it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1122.86it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.24it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 945.42it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.22it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1031.27it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.12it/s]\n1000\n999\n\n"
    }
   ],
   "source": [
    "import re\n",
    "sample_file_name = \"../dutch-language/data/sample-sentences-nlwiki.txt\"\n",
    "short_file_name = \"../dutch-language/data/short-sentences-nlwiki.txt\"\n",
    "full_file_name = \"../dutch-language/data/clean-sentences-nlwiki.txt\"\n",
    "corrected_file_name = \"../dutch-language/data/corrected-sentences-nlwiki.txt\"\n",
    "\n",
    "sentences_file_name = corrected_file_name\n",
    "positives_file_name = \"../dutch-language/data/positive-sentences-001.txt\"\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "TOTAL_SIZE = 10000\n",
    "\n",
    "regex_nd = re.compile(r'.*')\n",
    "\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/RoBERTa-003\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "with open(sentences_file_name, 'r') as sentences_file:\n",
    "    with open(positives_file_name, 'w') as positives_file:\n",
    "        total_count = 0\n",
    "        match_count = 0\n",
    "        batch = []\n",
    "        batch_count = len(batch)\n",
    "\n",
    "        for line in sentences_file:\n",
    "            # total size\n",
    "            total_count += 1\n",
    "            if (total_count >= TOTAL_SIZE):\n",
    "                break\n",
    "\n",
    "            # process lines\n",
    "            clean_line = line.rstrip()\n",
    "            if (regex_nd.match(clean_line)):\n",
    "                match_count += 1\n",
    "\n",
    "                # fill batch\n",
    "                batch_count += 1\n",
    "                batch.append(clean_line)\n",
    "                if batch_count >= BATCH_SIZE:\n",
    "                    # process batch\n",
    "                    predictions, raw_outputs = model.predict(batch)\n",
    "                    for index in range(len(predictions)):\n",
    "                        is_positive = (predictions[index] == 1) # can be more subtle later; no, maybe, true\n",
    "                        if (is_positive):\n",
    "                            positives_file.write(f\"1\\t{raw_outputs[index][0]}\\t{raw_outputs[index][1]}\\t{batch[index]}\\n\")\n",
    "                    batch = []\n",
    "                    batch_count = len(batch)\n",
    "\n",
    "print()\n",
    "print(total_count)\n",
    "print(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'simpletransformers.classification.classification_model.ClassificationModel'>\n"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/RoBERTa-003\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 44/44 [00:00<00:00, 633.48it/s]\n100%|██████████| 6/6 [00:01<00:00,  4.42it/s]\n[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1\n 0 1 1 1 1 1 1]\n[[ 4.4901423 -5.2648726]\n [ 4.579213  -5.2127857]\n [ 4.376685  -4.9772987]\n [ 4.5584965 -5.264288 ]\n [ 4.4977937 -5.1056805]\n [ 4.5773697 -5.109436 ]\n [ 4.5274673 -5.1332235]\n [ 4.5871463 -5.2608356]\n [ 4.556537  -5.2161202]\n [ 4.573585  -5.135414 ]\n [ 4.6195397 -5.185835 ]\n [ 4.4106946 -5.1367016]\n [-4.7086134  5.434552 ]\n [-4.5920606  5.3240337]\n [-4.6327615  5.1654444]\n [-4.776361   5.431048 ]\n [-4.6009827  5.388742 ]\n [-4.5932117  5.3681617]\n [-4.589336   5.354123 ]\n [-4.59776    5.1534967]\n [-4.6180773  5.1778216]\n [-4.64323    5.4163637]\n [-4.7370095  5.449645 ]\n [-4.5764985  5.0975075]\n [ 2.7234263 -2.864954 ]\n [ 4.547414  -5.14522  ]\n [ 4.445912  -5.053501 ]\n [ 4.256452  -4.8829684]\n [ 4.4687257 -5.109558 ]\n [ 4.4301257 -5.07444  ]\n [ 4.5616384 -5.1964564]\n [ 4.261184  -4.685912 ]\n [ 4.438639  -5.019965 ]\n [ 4.3783913 -4.914234 ]\n [-4.6018367  5.3245087]\n [-4.7017856  5.515843 ]\n [-4.6167684  5.3864737]\n [ 4.096218  -4.4969306]\n [-4.6056914  5.1128902]\n [-4.5884047  5.4026737]\n [-4.66569    5.3663335]\n [-4.6546     5.137302 ]\n [-4.5950265  5.075101 ]\n [-4.6348624  5.073843 ]]\n\n"
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict([\n",
    "    \"Ik word nieuwsgierig.\",\n",
    "    \"Hoe word je gevraagd?\",\n",
    "    \"Wat wordt je gevraagd?\",\n",
    "    \"Wat word je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zend een pakje.\",\n",
    "    \"Ik zend je een pakje.\",\n",
    "    \"Ik zend u een heel mooie trui.\",\n",
    "    \"Je zendt het toch nog vandaag op, hoop ik.\", #\n",
    "    \"Jij zendt een hele grote doos naar oma.\",\n",
    "    \"Zend je dat straks uit?\", #\n",
    "    \"Zend jij echt die fiets via de post?\",\n",
    "    \"Welke baas zendt je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik wordt nieuwsgierig.\",\n",
    "    \"Hoe wordt je gevraagd?\",\n",
    "    \"Wat word je gevraagd?\",\n",
    "    \"Wat wordt je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zendt een pakje.\",\n",
    "    \"Ik zendt je een pakje.\",\n",
    "    \"Ik zendt u een heel mooie trui.\", #\n",
    "    \"Je zend het toch nog vandaag op, hoop ik.\",\n",
    "    \"Jij zend een hele grote doos naar oma.\",\n",
    "    \"Zendt je dat straks uit?\", #\n",
    "    \"Zendt jij echt die fiets via de post?\",\n",
    "    \"Welke baas zend je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # Trying other words\n",
    "    # Correct spelling\n",
    "    \"Ik vind dit toch niet zo mooi.\",\n",
    "    \"Wat vind jij van al die aandacht?\",\n",
    "    \"Hoe vind ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vindt.\",\n",
    "    \"Hoe zwaar vindt hij de opleiding?\",\n",
    "\n",
    "    \"Ik loop er zo maar voorbij.\",\n",
    "    \"Loop jij ook zo snel?\",\n",
    "    \"Je loopt daar beter niet telkens over.\",\n",
    "    \"Jij loopt echt helemaal naar zee?\",\n",
    "    \"En daarom loopt hij er met een grote bocht omheen.\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik vindt dit toch niet zo mooi.\",\n",
    "    \"Wat vindt jij van al die aandacht?\",\n",
    "    \"Hoe vindt ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vind.\", # Incorrectly evaluated to \"0\"\n",
    "    \"Hoe zwaar vind hij de opleiding?\",\n",
    "\n",
    "    \"Ik loopt er zo maar voorbij.\",\n",
    "    \"Loopt jij ook zo snel?\",\n",
    "    \"Je loop daar beter niet telkens over.\",\n",
    "    \"Jij loop echt helemaal naar zee?\",\n",
    "    \"En daarom loop hij er met een grote bocht omheen.\"\n",
    "])\n",
    "print()\n",
    "print(predictions)\n",
    "print(raw_outputs)\n",
    "\n",
    "# Expected           [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-002 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1]\n",
    "# Actual RoBERTa-003 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual    BERT-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bita71a60f45b8e4338b01992b37d5c2d2a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}