{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "sample_file_name = \"../dutch-language/data/sample-sentences-nlwiki.txt\"\n",
    "short_file_name = \"../dutch-language/data/short-sentences-nlwiki.txt\"\n",
    "full_file_name = \"../dutch-language/data/clean-sentences-nlwiki.txt\"\n",
    "corrected_file_name = \"../dutch-language/data/corrected-sentences-nlwiki.txt\"\n",
    "\n",
    "sentences_file_name = corrected_file_name\n",
    "positives_file_name = \"../dutch-language/data/positive-sentences-002.txt\"\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "TOTAL_SIZE = 10000000\n",
    "\n",
    "regex_nd = re.compile(r'.*')\n",
    "\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/RoBERTa-004\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "with open(sentences_file_name, 'r') as sentences_file:\n",
    "    with open(positives_file_name, 'w') as positives_file:\n",
    "        total_count = 0\n",
    "        match_count = 0\n",
    "        batch = []\n",
    "        batch_count = len(batch)\n",
    "\n",
    "        for line in sentences_file:\n",
    "            # process lines\n",
    "            clean_line = line.rstrip()\n",
    "            if (regex_nd.match(clean_line)):\n",
    "                match_count += 1\n",
    "\n",
    "                # fill batch\n",
    "                batch_count += 1\n",
    "                batch.append(clean_line)\n",
    "                if batch_count >= BATCH_SIZE:\n",
    "                    # process batch\n",
    "                    predictions, raw_outputs = model.predict(batch)\n",
    "                    for index in range(len(predictions)):\n",
    "                        is_positive = (predictions[index] == 1) # can be more subtle later; no, maybe, true\n",
    "                        if (is_positive):\n",
    "                            positives_file.write(f\"1\\t{raw_outputs[index][0]}\\t{raw_outputs[index][1]}\\t{batch[index]}\\n\")\n",
    "                    batch = []\n",
    "                    batch_count = len(batch)\n",
    "\n",
    "            # total count\n",
    "            total_count += 1\n",
    "            if (total_count >= TOTAL_SIZE):\n",
    "                break\n",
    "\n",
    "\n",
    "print()\n",
    "print(total_count)\n",
    "print(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'simpletransformers.classification.classification_model.ClassificationModel'>\n"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "#    \"roberta\", \"outputs/RoBERTa-006\", use_cuda=True\n",
    "    \"bert\", \"outputs/BERT-002\", use_cuda=True\n",
    "\n",
    ")\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 44/44 [00:00<00:00, 1093.12it/s]\n100%|██████████| 6/6 [00:01<00:00,  4.19it/s]\n[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1\n 0 1 1 1 1 1 1]\n[[ 5.480039  -5.5231433]\n [ 5.224986  -5.4824595]\n [ 5.391847  -5.5476246]\n [ 5.449721  -5.60282  ]\n [ 5.1760144 -5.5311527]\n [ 5.262928  -5.534521 ]\n [ 4.863189  -5.0584745]\n [ 5.346662  -5.6910825]\n [ 5.370072  -5.704945 ]\n [ 5.2930503 -5.7360206]\n [ 5.3439794 -5.693661 ]\n [ 5.238829  -5.612129 ]\n [-5.3600774  5.54054  ]\n [-5.0608287  5.33169  ]\n [-5.3027263  5.481593 ]\n [-5.2946205  5.415605 ]\n [-5.315498   5.537039 ]\n [-5.3030295  5.4397826]\n [-5.2565784  5.489816 ]\n [-5.2055383  5.110843 ]\n [-5.337029   5.358834 ]\n [-5.2701774  5.5503774]\n [-5.3040547  5.554106 ]\n [-5.319076   5.359827 ]\n [ 2.3163333 -2.5617633]\n [ 5.2101216 -5.570829 ]\n [ 5.2929597 -5.635382 ]\n [ 5.403548  -5.6927085]\n [ 5.4403987 -5.7646785]\n [ 4.9500036 -5.3146133]\n [ 5.3127112 -5.653363 ]\n [ 5.42279   -5.703942 ]\n [ 5.364927  -5.700518 ]\n [ 5.456098  -5.7365465]\n [-5.340734   5.5525985]\n [-5.3864894  5.5570216]\n [-5.315711   5.5507507]\n [ 5.056012  -5.4528246]\n [-5.3392053  5.456859 ]\n [-5.2326274  5.4674363]\n [-5.274923   5.544041 ]\n [-5.327382   5.2809687]\n [-5.369781   5.367365 ]\n [-5.2624516  5.260819 ]]\n\n"
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict([\n",
    "    \"Ik word nieuwsgierig.\",\n",
    "    \"Hoe word je gevraagd?\",\n",
    "    \"Wat wordt je gevraagd?\",\n",
    "    \"Wat word je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zend een pakje.\",\n",
    "    \"Ik zend je een pakje.\",\n",
    "    \"Ik zend u een heel mooie trui.\",\n",
    "    \"Je zendt het toch nog vandaag op, hoop ik.\", #\n",
    "    \"Jij zendt een hele grote doos naar oma.\",\n",
    "    \"Zend je dat straks uit?\", #\n",
    "    \"Zend jij echt die fiets via de post?\",\n",
    "    \"Welke baas zendt je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik wordt nieuwsgierig.\",\n",
    "    \"Hoe wordt je gevraagd?\",\n",
    "    \"Wat word je gevraagd?\",\n",
    "    \"Wat wordt je opdringerig, zeg!\",\n",
    "\n",
    "    \"Ik zendt een pakje.\",\n",
    "    \"Ik zendt je een pakje.\",\n",
    "    \"Ik zendt u een heel mooie trui.\", #\n",
    "    \"Je zend het toch nog vandaag op, hoop ik.\",\n",
    "    \"Jij zend een hele grote doos naar oma.\",\n",
    "    \"Zendt je dat straks uit?\", #\n",
    "    \"Zendt jij echt die fiets via de post?\",\n",
    "    \"Welke baas zend je nu helemaal naar London voor 1 klant?\",\n",
    "\n",
    "    # Trying other words\n",
    "    # Correct spelling\n",
    "    \"Ik vind dit toch niet zo mooi.\",\n",
    "    \"Wat vind jij van al die aandacht?\",\n",
    "    \"Hoe vind ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vindt.\",\n",
    "    \"Hoe zwaar vindt hij de opleiding?\",\n",
    "\n",
    "    \"Ik loop er zo maar voorbij.\",\n",
    "    \"Loop jij ook zo snel?\",\n",
    "    \"Je loopt daar beter niet telkens over.\",\n",
    "    \"Jij loopt echt helemaal naar zee?\",\n",
    "    \"En daarom loopt hij er met een grote bocht omheen.\",\n",
    "\n",
    "    # With spelling mistake\n",
    "    \"Ik vindt dit toch niet zo mooi.\",\n",
    "    \"Wat vindt jij van al die aandacht?\",\n",
    "    \"Hoe vindt ik nu de ingang?\",\n",
    "    \"Het is toch erg dat hij dat niet vind.\", # Incorrectly evaluated to \"0\"\n",
    "    \"Hoe zwaar vind hij de opleiding?\",\n",
    "\n",
    "    \"Ik loopt er zo maar voorbij.\",\n",
    "    \"Loopt jij ook zo snel?\",\n",
    "    \"Je loop daar beter niet telkens over.\",\n",
    "    \"Jij loop echt helemaal naar zee?\",\n",
    "    \"En daarom loop hij er met een grote bocht omheen.\"\n",
    "])\n",
    "print()\n",
    "print(predictions)\n",
    "print(raw_outputs)\n",
    "\n",
    "# Expected           [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual RoBERTa-002 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1]\n",
    "# Actual RoBERTa-003 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1]\n",
    "# Actual    BERT-001 [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the strong positives (fp) to examples negatives\n",
    "# cat positive-sentences-processed.txt | grep '^1.*\\-[34]\\.' | sed 's/.*\\t\\(..*\\)$/    [\"\\1\", 0],/' > strong-positives-to-correct.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'simpletransformers.classification.classification_model.ClassificationModel'>\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1558.69it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.32it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1906.63it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.22it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1783.01it/s]\n100%|██████████| 13/13 [00:02<00:00,  4.41it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1512.99it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.06it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1527.05it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.10it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1821.72it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.25it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1606.07it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.21it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1730.19it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.17it/s]\nINFO:simpletransformers.classification.classification_model: Converting to features started. Cache is not used.\n100%|██████████| 100/100 [00:00<00:00, 1570.38it/s]\n100%|██████████| 13/13 [00:03<00:00,  4.23it/s]\n954\n954\n\n"
    }
   ],
   "source": [
    "# This is an experiment testing the algorithm on the Dutch language M.Sc. thesis of my daughter,\n",
    "# one day before the due date ... Tested with newest RoBERTa and BERT based model, trained on\n",
    "# exactly the same training (and validation) set:\n",
    "#\n",
    "# source data: 954 Dutch sentences written by my daughter about animation and psychology.\n",
    "#\n",
    "# RoBERTa: 0 positives ; I presume 0 or low amount of false negatives (low amount of actual positives in the source after manual proof reading)\n",
    "# So this is \"good\", 0 false positives.\n",
    "\n",
    "# BERT: 4 false positives; I presume 0 or low amount of false negatives (same reasoning)\n",
    "# \n",
    "# The 4 false positives of BERT where\n",
    "# 1\t-4.757866382598877\t4.64712381362915\tIn hoofdstuk 5 bekijk ik op welke manieren animatiefilm op dit moment al wordt geïmplementeerd in het therapeutische landschap.\n",
    "# 1\t-5.1004133224487305\t5.195034503936768\tWel vond ik enkele case studies over de manieren waarop animatiefilm zoal geïmplementeerd wordt in de Re-animation benadering (Mason, 2009).\n",
    "# 1\t-4.971858501434326\t5.104990005493164\tNaast deze twee benaderingen vond ik nog een aantal andere projecten terug waarin animatiefilm wordt gemaakt binnen de therapeutische ruimte, maar waarover minder informatie terug te vinden is of waarvan het niet duidelijk is of ze op dit moment nog actief toegepast worden.\n",
    "# 1\t-1.145717978477478\t0.7887341976165771\tWanneer ik de films sorteer op datum van release, wordt het duidelijk dat de films met een sterk en statistisch significant stereotiep beeld vooral de oudere Disney films betreffen.\n",
    "\n",
    "import re\n",
    "corrected_file_name = \"../dutch-language/data/thesis-animatie_05_31-sentences-clean-end.txt\"\n",
    "\n",
    "sentences_file_name = corrected_file_name\n",
    "positives_file_name = \"../dutch-language/data/positive-sentences-animatie-001.txt\"\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "TOTAL_SIZE = 10000\n",
    "\n",
    "regex_nd = re.compile(r'.*')\n",
    "\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"outputs/BERT-002\", use_cuda=True\n",
    "# \"roberta\", \"outputs/RoBERTa-006\", use_cuda=True\n",
    ")\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "with open(sentences_file_name, 'r') as sentences_file:\n",
    "    with open(positives_file_name, 'w') as positives_file:\n",
    "        total_count = 0\n",
    "        match_count = 0\n",
    "\n",
    "        batch = []\n",
    "        batch_count = len(batch)\n",
    "\n",
    "        for line in sentences_file:\n",
    "            # process lines\n",
    "            clean_line = line.rstrip()\n",
    "            if (regex_nd.match(clean_line)):\n",
    "                match_count += 1\n",
    "\n",
    "                # fill batch\n",
    "                batch_count += 1\n",
    "                batch.append(clean_line)\n",
    "                if batch_count >= BATCH_SIZE:\n",
    "                    # process batch\n",
    "                    predictions, raw_outputs = model.predict(batch)\n",
    "                    for index in range(len(predictions)):\n",
    "                        is_positive = (predictions[index] == 1) # can be more subtle later; no, maybe, true\n",
    "                        if (is_positive):\n",
    "                            positives_file.write(f\"1\\t{raw_outputs[index][0]}\\t{raw_outputs[index][1]}\\t{batch[index]}\\n\")\n",
    "                    batch = []\n",
    "                    batch_count = len(batch)\n",
    "\n",
    "            # total count\n",
    "            total_count += 1\n",
    "            if (total_count >= TOTAL_SIZE):\n",
    "                break\n",
    "\n",
    "\n",
    "print()\n",
    "print(total_count)\n",
    "print(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bita71a60f45b8e4338b01992b37d5c2d2a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}